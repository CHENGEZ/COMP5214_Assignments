{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: the loss is 1.5432354639689128\n",
      "epoch 1: the loss is 0.46465347771644594\n",
      "epoch 2: the loss is 0.32292920451958973\n",
      "epoch 3: the loss is 0.25952607463995614\n",
      "epoch 4: the loss is 0.22114930596351623\n",
      "epoch 5: the loss is 0.19427518376111985\n",
      "epoch 6: the loss is 0.1740309941569964\n",
      "epoch 7: the loss is 0.15817248942255974\n",
      "epoch 8: the loss is 0.14527411709427834\n",
      "epoch 9: the loss is 0.13502358359098435\n",
      "epoch 10: the loss is 0.12608575797080993\n",
      "epoch 11: the loss is 0.11886040800611178\n",
      "epoch 12: the loss is 0.11242392224669456\n",
      "epoch 13: the loss is 0.10696157859563828\n",
      "epoch 14: the loss is 0.10162901850640774\n",
      "epoch 15: the loss is 0.09703815984129906\n",
      "epoch 16: the loss is 0.09326650041341782\n",
      "epoch 17: the loss is 0.08929327138662338\n",
      "epoch 18: the loss is 0.08604143045445284\n",
      "epoch 19: the loss is 0.0824216425170501\n",
      "the loss on test data is 0.09596542377207189\n",
      "The accuracy on the testing data is 0.9698\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from FileLoader import *\n",
    "\n",
    "batch_size = 64\n",
    "num_epoch = 20\n",
    "\n",
    "\n",
    "train_images, train_labels = load_train_data()\n",
    "full_train_data = to_tensor(train_images)[0, :, :]\n",
    "full_train_target = []\n",
    "for i in range(60000):\n",
    "    full_train_target.append(np.zeros(10))\n",
    "for i in range(60000):\n",
    "    k = train_labels[i]\n",
    "    full_train_target[i][k] = 1\n",
    "full_train_target = np.array(full_train_target)\n",
    "full_train_target = torch.from_numpy(full_train_target)\n",
    "\n",
    "\n",
    "test_images, test_labels = load_test_data()\n",
    "full_test_data = to_tensor(test_images)[0, :, :]\n",
    "full_test_target = []\n",
    "for i in range(10000):\n",
    "    full_test_target.append(np.zeros(10))\n",
    "for i in range(10000):\n",
    "    k = test_labels[i]\n",
    "    full_test_target[i][k] = 1\n",
    "full_test_target = np.array(full_test_target)\n",
    "full_test_target = torch.from_numpy(full_test_target)\n",
    "\n",
    "full_train_data = full_train_data.reshape(60000, 1, 28, 28)\n",
    "full_test_data = full_test_data.reshape(10000, 1, 28, 28)\n",
    "\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # feature map will have size 24*24\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.avgPool1 = torch.nn.AvgPool2d(2, 2)  # down sampled to size 12*12\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)  # featur map will have size 8*8\n",
    "        self.avgPool2 = torch.nn.AvgPool2d(2, 2)  # down sampled to size 4*4\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.conv1(X)\n",
    "        X = self.avgPool1(X)\n",
    "        X = self.conv2(X)\n",
    "        X = self.avgPool2(X)\n",
    "        X = torch.flatten(X, 1)\n",
    "        X = self.fc1(X)\n",
    "        X = torch.tanh(X)\n",
    "        X = self.fc2(X)\n",
    "        X = torch.tanh(X)\n",
    "        X = self.fc3(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# the trainning loop\n",
    "for epoch in range(num_epoch):  # 20 epochs\n",
    "    cnn.train()\n",
    "    permutation = torch.randperm(60000)\n",
    "    train_loss_in_this_epoch = 0.0\n",
    "\n",
    "    # batch size of 64, takes 938 iterations to go through whole dataset\n",
    "    for batch in range(60000//batch_size + 1):\n",
    "        if batch != 60000//batch_size:\n",
    "            this_batch_size = batch_size\n",
    "            input = np.zeros(batch_size*28*28).reshape(batch_size, 1, 28, 28)\n",
    "            input = torch.from_numpy(input)\n",
    "            for i in range(batch_size):\n",
    "                input[i] = full_train_data[permutation[batch*batch_size+i]]\n",
    "            input = input.to(torch.float32)\n",
    "\n",
    "            target = np.zeros(batch_size*10).reshape(batch_size, 10)\n",
    "            target = torch.from_numpy(target)\n",
    "            for i in range(batch_size):\n",
    "                target[i] = full_train_target[permutation[batch*batch_size+i]]\n",
    "            target = target.to(torch.float32)\n",
    "\n",
    "        else:\n",
    "            this_batch_size = 60000-batch*batch_size\n",
    "            input = np.zeros(this_batch_size*28 *\n",
    "                             28).reshape(this_batch_size, 1, 28, 28)\n",
    "            for i in range(this_batch_size):\n",
    "                input[i] = full_train_data[permutation[batch*batch_size+i]]\n",
    "            input = torch.from_numpy(input)\n",
    "            input = input.to(torch.float32)\n",
    "\n",
    "            target = np.zeros(this_batch_size*10).reshape(this_batch_size, 10)\n",
    "            for i in range(this_batch_size):\n",
    "                target[i] = full_train_target[permutation[batch*batch_size+i]]\n",
    "            target = torch.from_numpy(target)\n",
    "            target = target.to(torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = cnn(input)\n",
    "        loss = criterion(prediction, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_in_this_epoch += loss.item()*this_batch_size\n",
    "\n",
    "    print(\"epoch\", epoch, end=\": \")\n",
    "    print(\"the loss is\", train_loss_in_this_epoch/60000)\n",
    "\n",
    "test_prediction = cnn(full_test_data)\n",
    "test_loss = criterion(test_prediction, full_test_target)\n",
    "print(\"the loss on test data is\", test_loss.item())\n",
    "\n",
    "predicted_numbers = []\n",
    "for i in range(10000):\n",
    "    predicted_number = torch.argmax(test_prediction[i]).item()\n",
    "    predicted_numbers.append(predicted_number)\n",
    "predicted_numbers = np.array(predicted_numbers)\n",
    "\n",
    "num_error = 0\n",
    "for truth, prediction in zip(test_labels, predicted_numbers):\n",
    "    if truth != prediction:\n",
    "        num_error += 1\n",
    "print(\"The accuracy on the testing data is\", 1-num_error/10000)\n",
    "\n",
    "###\n",
    "# the loss on test data is 0.09200327463574685\n",
    "# The accuracy on the testing data is 0.9716\n",
    "###"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea7655f8563b6b304d5ebbeaa9fbbcccb7096429f906efd7b44913c32e5b88a8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
